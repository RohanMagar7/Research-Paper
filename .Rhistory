value = if(category == "Approved"){
return(1)
}else{
return(0)
}
return(value)
}
cat <- apply(loan_subset[, "loan_status", drop = FALSE], 2, category)
category <- function(category) {
ifelse(category == "Approved", 1, 0)
}
cat <- apply(loan_subset[, "loan_status", drop = FALSE], 2, category)
View(cat)
category <- function(category) {
ifelse(category == "Rejected", 0, 1)
}
cat <- apply(loan_subset[, "loan_status", drop = FALSE], 2, category)
View(cat)
category <- function(category) {
ifelse(trimws(tolower(category)) == "approved", 1, 0)
}
cat <- apply(loan_subset[, "loan_status", drop = FALSE], 2, category)
View(cat)
loan_subset$loan_status <- cat
View(loan_subset)
grad <- function(grad){
ifelse(trimws(tolower(grad)) == 'Not Graduate', 0 , 1)
}
graduation <- apply(loan_subset[,"education" , drop=FALSE] , 2, grad)
View(grad())
View(grad)
View(graduation)
grad <- function(grad){
ifelse(trimws(tolower(grad)) == 'graduate', 1 , 0)
}
graduation <- apply(loan_subset[,"education" , drop=FALSE] , 2, grad)
View(graduation)
loan_subset$education <- graduation
View(loan_subset)
normalize <- function(x){
return((x-min(x))/(max(x)) - (min(x)) )
}
loan_subset$bank_asset_value <- apply(loan_subset[, "bank_asset_value", drop = FALSE], 2, normalize)
View(loan_subset)
View(loan_subset)
colnames(loan_subset) <- c("bank_asset_value", "no_of_dependents", "education" , "self_employed"
,"income_annum" , "loan_amount" , "loan_term" , "cibil_score", "residential_assets_value",
"commercial_assets_value" ,"luxury_assets_value" , "bank_asset_value" , "loan_status")
colnames(loan_subset) <- c("bank_asset_value", "no_of_dependents", "education" , "self_employed"
,"income_annum" , "loan_amount" , "loan_term" , "cibil_score", "residential_assets_value",
"commercial_assets_value" ,"luxury_assets_value" , "bank_asset_value" , "loan_status")
loan_subset <- as.matrix(loan_subset)
colnames(loan_subset) <- c("bank_asset_value", "no_of_dependents", "education" , "self_employed"
,"income_annum" , "loan_amount" , "loan_term" , "cibil_score", "residential_assets_value",
"commercial_assets_value" ,"luxury_assets_value" , "bank_asset_value" , "loan_status")
View(loan_subset)
View(loan_subset)
loan_subset <- as.data.frame(loan_subset)
selfemp <- function(category){
ifelse(trimws(tolower(category)) == 'yes' , 1 , 0 )
}
loan_subset$self_employed <- apply(loan_subset[,'self_employed',drop = FALSE] , 2, selfemp)
View(loan_subset)
loan_subset$bank_asset_value <- apply(loan_subset[, "bank_asset_value", drop = FALSE], 2, normalize)
loan_subset$residential_assets_value <- apply(loan_subset[,'residential_assets_value', drop=FALSE], 2 , normalize)
normalize <- function(x){
return((x-min(x))/(max(x)) - (min(x)) )
}
loan_subset$bank_asset_value <- apply(loan_subset[, "bank_asset_value", drop = FALSE], 2, normalize)
loan_subset$residential_assets_value <- apply(loan_subset[,'residential_assets_value', drop=FALSE], 2 , normalize)
loan_subset$income_annum <- apply(loan_subset[,'income_annum',drop=FALSE], 2, normalize)
loan_subset$loan_amount <- apply(loan_subset[,'loan_amount',drop = FALSE] , 2 , normalize)
loan_subset$commercial_assets_value <- apply(loan_subset[,'commercial_assets_value', drop = FALSE], 2, normalize)
loan_subset$cibil_score <- apply(loan_subset[,'cibil_score' , drop = FALSE] , 2, normalize)
loan_subset$loan_term <- apply(loan_subset[,'loan_term',drop = FALSE] , 2, normalize)
loan_subset$luxury_assets_value <- apply(loan_subset[,'luxury_assets_value', drop = FALSE] ,2 ,normalize)
View(loan_subset)
loan_subset <- loan %>%
select(bank_asset_value, no_of_dependents, education , self_employed
,income_annum , loan_amount , loan_term , cibil_score, residential_assets_value,
commercial_assets_value ,luxury_assets_value , bank_asset_value , loan_status
)
loan_subset <- as.data.frame(loan_subset)
normalize <- function(x){
return((x-min(x))/(max(x)) - (min(x)) )
}
loan_subset$bank_asset_value <- apply(loan_subset[, "bank_asset_value", drop = FALSE], 2, normalize)
loan_subset$residential_assets_value <- apply(loan_subset[,'residential_assets_value', drop=FALSE], 2 , normalize)
loan_subset$income_annum <- apply(loan_subset[,'income_annum',drop=FALSE], 2, normalize)
loan_subset$loan_amount <- apply(loan_subset[,'loan_amount',drop = FALSE] , 2 , normalize)
loan_subset$commercial_assets_value <- apply(loan_subset[,'commercial_assets_value', drop = FALSE], 2, normalize)
loan_subset$cibil_score <- apply(loan_subset[,'cibil_score' , drop = FALSE] , 2, normalize)
loan_subset$loan_term <- apply(loan_subset[,'loan_term',drop = FALSE] , 2, normalize)
loan_subset$luxury_assets_value <- apply(loan_subset[,'luxury_assets_value', drop = FALSE] ,2 ,normalize)
self_employed <- as.numeric(as.factor(loan_subset$self_employed))
loan_subset$education <- edu
category <- function(category) {
ifelse(trimws(tolower(category)) == "approved", 1, 0)
}
grad <- function(grad){
ifelse(trimws(tolower(grad)) == 'graduate', 1 , 0)
}
cat <- apply(loan_subset[, "loan_status", drop = FALSE], 2, category)
selfemp <- function(category){
ifelse(trimws(tolower(category)) == 'yes' , 1 , 0 )
}
loan_subset$self_employed <- apply(loan_subset[,'self_employed',drop = FALSE] , 2, selfemp)
graduation <- apply(loan_subset[,"education" , drop=FALSE] , 2, grad)
loan_subset$loan_status <- cat
loan_subset$education <- graduation
View(loan_subset)
path <- 'F:/R programming/learning/assignments/learning dataset/snads.csv'
dataset <- read.csv(path)
head(dataset)
sub <- dataset[3:5]
sub
sub$Purchased <- as.factor(sub$Purchased , levels=  c(0,1))
sub$Purchased <- factor(sub$Purchased , levels= c(0,1))
head(dataset)
head(sub)
View(sub)
set.seed(123)
install.packages("caTools")
library(caTools)
split_d <- sample.split(sub$Purchased, SplitRatio = 0.75 )
View(split_d))
View(split_d))
View(split_d)
split_d
sub.train <- subset(sub,split_d == TRUE)
sub.test <- subset(sub,split_d == FALSE)
nrow(sub.train)
nrow(sub.test)
nrow(sub)
traning_set[-3] <- scale(sub.train[-3])
traning_set <- scale(sub.train[-3])
traning_set
View(training_set)
View(traning_set)
View(sub)
View(traning_set)
sub.train[-3] <- scale(sub.train[-3])
View(sub.train)
sub.test[-3] <- scale(sub.test[-3])
pre <- knn(train = sub.train[-3],test = sub.test[-3], cl = sub.train[,3], k = 5 )
library(class)
pre <- knn(train = sub.train[-3],test = sub.test[-3], cl = sub.train[,3], k = 5 )
pre
View(pre)
### create confusion matrix
confmatrix <- table(sub.test[,3],pre)
confmatrix
View(iris)
#scale the dataset
iris[,1:4] <- scale(iris[,1:4])
View(iris)
View(iris)
library(caTools)
split_data <- sample.split(iris$Species , SplitRatio = 0.75)
iris.train <- subset(iris,split_data == TRUE)
iris.test <- subset(iris,split_data == FALSE)
nrow(iris.train)
nrow(iris.test)
nrow(iris)
View(iris.train)
View(iris.test)
# Extract Predicator variable ( x ) and target variable ( y )
trainX <- iris.train[,1:4]
testX <- iris.test[,1:4]
trainY <- iris.train$Species
testY <- iris.test$Species
# perform knn
knn.predict <- knn(train = trainX, test = testX , cl = trainY , k = 5)
knn.predict
testY
# evaluate model
conf_matrix <- table(prediccted = knn.predict , Actual = testY)
conf_matrix
### calculate accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
accuracy
print(paste('accuracy',round(accuracy)))
print(paste('accuracy',round(accuracy * 100 )))
print(paste('accuracy',round(accuracy * 100  , 2)))
### fint optimal K using Error Rate
# finding the best k values
error_rate <- numeric(15)
error_rate
print(paste('accuracy',round(accuracy * 100  , 2)))
### fint optimal K using Error Rate
# finding the best k values
error_rate <- numeric(15)
error_rate
for ( k in 1:15){
knn.predict <- knn(train = trainX, test = testX , cl = trainY , k = k )
error_rate[k] <- mean(knn.predict != testY)
}
error_rate
error_df <- data.frame(k = 15 , error_rate)
error_df
View(error_df)
# plot K vs Error Rate
ggplot(error_df , aes(x = k , y = error_rate)) +
geom_line(color = 'green')
library(ggplot2)
# plot K vs Error Rate
ggplot(error_df , aes(x = k , y = error_rate)) +
geom_line(color = 'green')
error_df <- data.frame(k = 1:15 , error_rate)
error_df
View(error_df)
# plot K vs Error Rate
ggplot(error_df , aes(x = k , y = error_rate)) +
geom_line(color = 'green')
# plot K vs Error Rate
ggplot(error_df , aes(x = k , y = error_rate)) +
geom_line(color = 'green') +
geom_point(color = 'blue')
# plot K vs Error Rate
ggplot(error_df , aes(x = k , y = error_rate)) +
geom_line(color = 'green') +
geom_point(color = 'blue')+
ggtitle('Error Rate Vs K in KNN') +
xlab('K ( Number of Neighbors ) ') +
ylab(' Error Rate ')
# plot K vs Error Rate
ggplot(error_df , aes(x = k , y = error_rate)) +
geom_line(color = 'green') +
geom_point(color = 'blue')+
ggtitle('Error Rate Vs K in KNN') +
xlab('K ( Number of Neighbors ) ') +
ylab(' Error Rate ') +
theme_minimal()
library(caTools)
library(rpart)
dt <- read.csv(path)
head(dt)
dt <- dt[3:5]
dt$Purchased <- factor(dt$Purchased , levels = c(0,1))
split <- sample.split(dt$Purchased , SplitRatio =  0.75)
dt.train <- subset(dt , split == TRUE)
dt.test <- subset(dt,split == FALSE)
nrow(dt)
nrow(dt.train)
nrow(dt.test)
View(dt.train)
dt[,1:2] <- scale(dt[,1:2])
View(dt.train)
dt[,1:2] <- scale(dt[,1:2])
dt$Purchased <- factor(dt$Purchased , levels = c(0,1))
split <- sample.split(dt$Purchased , SplitRatio =  0.75)
dt.train <- subset(dt , split == TRUE)
dt.test <- subset(dt,split == FALSE)
# sampling
tran_X <- dt.train[]
View(dt.train)
# sampling
tran_X <- dt.train[,1:2]
View(tran_X)
test_X <- dt[,3]
View(test_X)
View(train_X)
# sampling
train_X <- dt[,1:2]
test_X <- dt[,1:2]
test_X <- dt[,3]
View(train_X)
test_X <- dt[,1:2]
test_X <- dt[3]
View(train_X)
View(test_X)
dtclassifier <- rpart(formula = Purchased ~ .,data = train_X)
dtclassifier <- rpart(formula = Purchased ~ .,data = dt.train)
dtclassifier
rpart.plot(dtclassifier, type = 4, extra = 101)
# Visualize the tree
rpart.plot(dtclassifier, type = 4, extra = 101)
install.packages("rpart.plot")
library(rpart.plot)
# Visualize the tree
rpart.plot(dtclassifier, type = 4, extra = 101)
# Visualize the tree
rpart.plot(dtclassifier, type = 2, extra = 101)
# Visualize the tree
rpart.plot(dtclassifier, type = 1, extra = 101)
# Visualize the tree
rpart.plot(dtclassifier, type = 5, extra = 101)
# Visualize the tree
rpart.plot(dtclassifier, type = 4, extra = 101)
####++++++++++++++++++++++++++++++++++++++++++++
library(rpart)
set.seed(123)
set.seed(123)
####++++++++++++++++++++++++++++++++++++++++++++
library(rpart)
set.seed(123)
View(test_data)
# split data ( 80)
train_index <- sample(1:nrow(iris) , 0.8 * nrow(iris))
train_data <- iris[train_index,]
test_data <- iris[-train_index,]
View(test_data)
View(test_data[-3])
View(test_data[-4])
View(test_data)
View(test_data[-5])
# make prediction on test data
df_prediction <- predict(dtclassifier, newdata = test_data[-5] , type = 'class')
## Train Decision Tree Classifier
dt_classfier <- rpart(Species ~ ., data = train_data ,method = 'class' )
# make prediction on test data
df_prediction <- predict(dtclassifier, newdata = test_data[-5] , type = 'class')
# split data ( 80)
train_index <- sample(1:nrow(iris) , 0.8 * nrow(iris))
train_data <- iris[train_index,]
test_data <- iris[-train_index,]
## Train Decision Tree Classifier
dt_classfier <- rpart(Species ~ ., data = train_data ,method = 'class' )
# make prediction on test data
df_prediction <- predict(dt_classfier, newdata = test_data[-5] , type = 'class')
df_prediction
rpart.plot(dt_classfier , type = 4 , extra = 101)
library(rpart.plot)
rpart.plot(dt_classfier , type = 4 , extra = 101)
View(train_X)
# evaluate the model
table(predicted = df_prediction , Actual = test_data$Species)
# evaluate the model
conf_matrix <- table(predicted = df_prediction , Actual = test_data$Species)
sum(diag(confmatrix))
diag_sum <- sum(diag(confmatrix))
sum_all <- sum(confmatrix)
print(diag_sum/sum_all)
paste('Accuracy', round((diag_sum/sum_all) * 100))
paste('Accuracy', round((diag_sum/sum_all) * 100 , 2))
paste('Accuracy', round((diag_sum/sum_all) * 100 ) , 2 )
paste('Accuracy', round((diag_sum/sum_all) * 100  , 2) )
paste('Accuracy', round(diag_sum/sum_all* 100  , 2) )
accuracy <- diag_sum / sum_all
paste('Accuracy', round(accuracy * 100  , 2) )
paste('Accuracy', round(accuracy * 100  , 4) )
iris_data <- iris[,-5]
# perform k - means
kmeans_result <- kmeans(iris_data , centers = 3 , nstart = 25)
# view cluster assignment
print(kmeans_result)
View(kmeans_result)
View(kmeans_result$cluster)
iris$cluster <- as.factor(kmeans_result$cluster)
View(iris)
library(ggplot2)
# scatter plot of clusters
ggplot(iris,aes(x = Sepal.Length, y = Sepal.Width , colour = cluster)) +
geom_point(size = 3 ) +
labs(
title = 'K-Means clustering of Iris Dataset',
x = 'Sepal Length ',
y = "sepal width"
) +
theme_minimal()
View(iris)
# Scatter plot with centroids
ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Cluster)) +
geom_point(size = 3, alpha = 0.6) +  # Plot data points
geom_point(data = centroids, aes(x = Sepal.Length, y = Sepal.Width),
color = "black", shape = 8, size = 5) +  # Plot centroids
labs(title = "K-Means Clustering of Iris Dataset with Centroids",
x = "Sepal Length", y = "Sepal Width") +
theme_minimal()
# Scatter plot with centroids
ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Cluster)) +
geom_point(size = 3, alpha = 0.6) +  # Plot data points
geom_point(data = centroids, aes(x = Sepal.Length, y = Sepal.Width),
color = "black", shape = 8, size = 5) +  # Plot centroids
labs(title = "K-Means Clustering of Iris Dataset with Centroids",
x = "Sepal Length", y = "Sepal Width") +
theme_minimal()
centers <- as.data.frame(kmeans_result$centers)
# Scatter plot with centroids
ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Cluster)) +
geom_point(size = 3, alpha = 0.6) +  # Plot data points
geom_point(data = centers, aes(x = Sepal.Length, y = Sepal.Width),
color = "black", shape = 8, size = 5) +  # Plot centroids
labs(title = "K-Means Clustering of Iris Dataset with Centroids",
x = "Sepal Length", y = "Sepal Width") +
theme_minimal()
# Scatter plot with centroids
ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = cluster)) +
geom_point(size = 3, alpha = 0.6) +  # Plot data points
geom_point(data = centers, aes(x = Sepal.Length, y = Sepal.Width),
color = "black", shape = 8, size = 5) +  # Plot centroids
labs(title = "K-Means Clustering of Iris Dataset with Centroids",
x = "Sepal Length", y = "Sepal Width") +
theme_minimal()
View(centers)
library(ggplot2)  # For visualization
library(dendextend)  # For better dendrogram visualization
library(dendextend)  # For better dendrogram visualization
install.packages("dendextend")
library(dendextend)  # For better dendrogram visualization
library(ggplot2)  # For visualization
library(dendextend)  # For better dendrogram visualization
iris.data <- scale(iris[,-5])
iris.data <- scale(iris[,-5])
data("iris")
iris.data <- scale(iris[,-5])
iris.data
distance_matrix <- dist(iris.data , method = 'eclidean')
distance_matrix <- dist(iris.data , method = 'euclidean')
hc <- hclust(distance_matrix , method = 'complete')
distance_matrix
View(distance_matrix)
View(hc)
# step 4 : visualize dendrogramm
# Basic dendrogram
plot(hc, main = "Hierarchical Clustering Dendrogram", sub = "", xlab = "", cex = 0.6)
View(hc)
# step 4 : visualize dendrogramm
# Basic dendrogram
plot(hc,main='Hierachical clustering Dendrogram' , sub = '' , xlab = '' , cex = 0.6)
View(dt_classfier)
# step 5 imrove the dendrogramm visualization
# convert to dendrogram object for customization
dend <- as.dendrogram(hc)
# plot enhance dendrogram
plot(dend, main = 'Colored Dendrogram of Iris Dataset')
View(dt)
# Step 6 : cut the tree from from center 🌴
clusters <- cutree(hc, k = 3)
# Add cluster labels to dataset
iris$Cluster <- as.factor(clusters)
# View first few rows
head(iris)
# Step 6 : cut the tree from from center 🌴
clusters <- cutree(hc, k = 3)
# Add cluster labels to dataset
iris$Cluster <- as.factor(clusters)
# plot the cluster
ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Cluster)) +
geom_point(size = 3, alpha = 0.7) +  # Scatter plot points
labs(title = "Hierarchical Clustering: Sepal Length vs Width",
x = "Sepal Length", y = "Sepal Width") +
theme_minimal()
View(iris_data)
# plot the cluster
ggplot(iris, aes(x = Sepal.Length , y = Sepal.Width , color = Cluster)) +
geom_point(size = 3 , alpha = 0.7) +
labs( title = 'Hierachical clustering : Sepal Length Vs width',
x = 'Sepal Length',
y = 'Sepal Width') +
theme_minimal()
View(iris.test)
x
n_sample <- 20
x <- matrix(rnorm(n_sample = 2 ), ncol = 2 )
x <- matrix(rnorm(n_samples = 2 ), ncol = 2 )
x <- matrix(rnorm(n_samples = n_sample), ncol = 2 )
x <- matrix(rnorm(n_sample), ncol = 2 )
x
hierachical_iris <- hclust(distance_matrix, method = 'complete')
# plot the dendrogram
plot(hierachical_iris , main = 'Hierachical clusering Dendrogram ', xlab = 'sample index' , ylab = 'distance')
View(iris.test)
clusters <- cutree(hierachical_iris, i )
clusters <- cutree(hierachical_iris, k )
# Visualize the clusters
plot(x , col = clusters , pch = 19 , main = 'Hierachical clustering ' , xlab = 'Featur' , ylab = 'feature 2')
View(train_data)
library(ggplot2)
library(ggfortify)
library(plotly)
library(ggplot2)
library(ggfortify)
library(plotly)
data("iris")
pca_result <- prcomp(iris_numeric , centers = TRUE , scale = TRUE)
iris_numeric <- iris[,1:4]
pca_result <- prcomp(iris_numeric , centers = TRUE , scale = TRUE)
pca_result <- prcomp(iris_numeric , center = TRUE , scale = TRUE)
iris_numeric <- iris[,1:4]
pca_result <- prcomp(iris_numeric , center = TRUE , scale = TRUE)
View(pca_result)
std_dev
std_dev <- pca_result$sdev
std_dev
prop_variance <- (std_dev ^ 2 )/sum(std_dev^2)
prop_variance
cum_variance <- cumsum(prop_variance)
cum_variance
print(data.frame(pc = paste0("PC", 1 : length(std_dev)) , std_Dev = std_dev , prop_var = prop_variance , cum_var = cum_variance))
ggplot(data.frame(pc = factor(1:4) , variance = prop_variance) , aes(x = pc, y = variance )) +
geom_bar(stat = 'identity' , fill = 'blue') +
ggtitle('scale plot') +
theme_minimal()
View(pca_result)
pca_df <- data.frame(pca_result$x , Species = iris$Species)
ggplot(pca_df , aes(x = PC1 , y = PC2 , color = Species)) +
geom_point(size = 3 ) +
ggtitle("PcA : First two components ") +
theme_minimal()
View(pca_df)
plot_ly(pca_df , x = ~ PC1 , y = ~PC2 , z = ~PC3, color = ~Species , colors = c('red','blue','green')) %>%
add_markers() %>%
layout(title = "3D PCA visualization",
scene = list(xaxis = list(xasix = list(title = 'pc1') , yaxis = list(title = 'pc2'), zaxis = list(title = 'pc3')))
)
View(sub.train)
plot_ly(pca_df , x = ~ PC1 , y = ~PC2 , z = ~PC3, color = ~Species , colors = c('red','blue','green')) %>%
add_markers() %>%
layout(title = "3D PCA visualization",
scene = list(xaxis = list(xasix = list(title = 'pc1') , yaxis = list(title = 'pc2'), zaxis = list(title = 'pc3')))
)
